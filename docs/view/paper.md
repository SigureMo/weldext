# 神经网络在焊接过程中的应用现状及发展趋势分析

## 摘要

## 1 引言

焊接是一种以加热或加压方式对材料进行接合的工艺及技术。其操作要求严苛，对操作人员有着较高的熟练要求，且工作环境恶劣，操作人员常常处于高危且有毒的环境中，存在着很多的潜在危险[1]。而焊接机器人的应用能大大改善上述问题。它能够提供稳定且均一的焊缝，使得焊缝质量更有保障[2]。同时也大大改善了工业机械操作人员的生活和劳动条件，操作人员只需要方便地装卸工件，就已经可以有效避免操作中接触一些有毒的化学气体和弧光等有害元素。另外，由于焊接机器人可以二十四小时连续生产，因此它的生产效率更高。由此可见，智能化与自动化的生产已经逐渐成为了现代机械焊接加工技术进步与发展的必然趋势。

现代焊接机器人主要根据视觉、电弧、力矩等相关传感器获取焊接环境的相关信息，经过智能化控制与调节来优化自身的焊接轨迹，从而完成复杂的焊接任务[3]。然而近年来焊接机器人的应用飞速增长，同时焊接机器人的应用领域也逐渐趋向复杂多变，焊接控制技术迎来了极大的挑战。由于焊接过程充满了强烈的弧光辐射、焊渣的飞溅、灰尘等不确定因素，还有着高温、氧化等等问题[4]，都会对焊接机器人所接收到的传感器数据产生影响，以至于焊接产生偏差，影响焊缝质量。为了使得焊接机器人能够应对这些问题，焊接机器人必须有比较强的抗干扰能力。

为了使得焊接机器人拥有智能控制能力，机器学习算法必不可少。机器学习算法以推理与学习为核心，涉及了概率论、统计学等多门学科，能够从复杂的数据中学习到知识并将其应用在实际生产中。在机器学习算法中最为突出的方法是神经网络模型，它拥有非常强的自适应能力以及极佳的抗干扰性，这意味它可以在焊接过程中拥有更高的控制精度以及更低的错误率。

随着近年来深度学习技术的发展，神经网络的性能不断提高，在图像处理等等很多领域都取得了突破性的进展，这为焊接机器人的智能化提供了强有力的技术支持。此外，神经网络还在强化学习等方面得到了广泛的应用，这使得焊接机器人能够应对更加复杂的环境，为焊接完全自动化控制奠定了基础。

## 2 神经网络研究现状

神经网络（Neural Network，NN）的相关研究在很早以前就已经出现，而如今已经形成了一个相当大的多学科交叉的学科领域[5]。通常所说的神经网络是指人工神经网络（ANN），是机器学习领域中的一种模仿生物神经网络的结构和功能的数学模型或计算模型。

### 2.1 神经网络基本模型

#### 2.1.1 M-P 神经元模型

生物神经网络最基本的单元是生物神经元（neuron）。生物神经元的基本结构如图 1.1 所示，当一个神经元的电位达到一个阈值时，它会转变为“兴奋”状态，进而向下一个神经元传递神经递质，以影响下一个神经元的电位。生物神经元彼此连接形成网状结构，从而能够完成复杂的功能。

![Figure 2.1](../_media/paper/Figure2.1.jpg)

图 2.1 生物神经元结构

1943 年，McCulloch 与 Pitts 将上述情形抽象为一个如图 1.2 所示的简单的数学模型，也就是人工神经网络中最经典的 “M-P 神经元模型”[6]。类似于生物神经元的概念，M-P 神经元接收前驱 $n$ 个神经元的输入信号，并对每个信号赋予一定的权重进行加和，得到 $\sum\limits_{i=1}^n w_i x_i$，将其作为该神经元的信号。当该信号值达到阈值 $\theta$ 时向下一个神经元传递信号，也就是向后一神经元传递信号 $y = f(\sum\limits_{i=1}^n w_i x_i - \theta)$。其中 $f$ 为激活函数，这里使用的是阶跃函数，也即 $f(x) = sgn(x)$。然而由于阶跃函数具有不连续、不光滑等问题，实际应用中常使用 $Sigmoid$ 函数作为激活函数。

![Figure 2.2](../_media/paper/Figure2.2.png)

图 2.2 M-P 神经元结构

#### 2.1.2 神经网络结构

类似于生物神经网络，将神经元彼此连接便形成了人工神经网络。单层神经网络只包含一个输入层和一个输出层，由于输入层神经元仅接收外界输入而不对数据进行处理，所以输入层往往不计入层数中。单层神经网络的处理能力有限，很难解决线性不可分的问题，所以常见的神经网络一般是两层以上的。两层的神经网络又称为单隐层神经网络（如图 1.3），它包含了一个输入层（input layer）、一个隐藏层（hidden layer）和一个输出层（output layer）。输入层和输出层分别接收外界输入和将输出传输给外界，隐藏层和输出层都有着数据处理的功能。

![Figure 2.3](../_media/paper/Figure2.3.png)

图 2.3 单隐层神经网络结构

多层神经元相互堆叠形成的深层神经网络对数据有着极强的拟合能力，近年来神经网络层数的极限不断提高，在此基础上发展出来了新的学科——深度学习。深度神经网络通过多层的处理，逐渐将低层特征表示转化为高层特征表示，使得之后用简单模型即可完成复杂的学习任务。近年来深度学习技术不断发展，在计算机视觉、自然语言处理等方面均取得了重大的突破。

#### 2.1.3 其他神经网络模型

M-P 神经元具有简洁且且高效的运算方式，这使得现在大多数神经网络都是基于 M-P 神经元的，深度神经网络也不例外。它们凭借着不同的网络结构，对某一种或一类特定的问题都有着较强的处理能力。比如擅长处理计算机视觉问题的卷积神经网络（Convolutional neural network, CNN）、擅长处理非欧拓扑结构数据的图神经网络（Graph neural network, GNN）、擅长自然语言处理的 Transformer 等等。

除此之外，还有一些神经网络采用了新型的神经元结构。比如神经网络中有一类模型是为网络状态定义一个“能量”（energy），网络的优化目标是最小化这个能量函数。受限玻尔兹曼机（Restricted Boltzmann Machine，RBM）就是这样的一种网络，它常用对比散度算法来进行训练，能够取得不错的性能。近期张绍群、周志华等人参考了生物神经网络中树突浓度会在持续接受刺激后发生一定的变化，将该行为描述为一个二元二值的函数，并将该模型称为 Flexible Transmitter，简称 FT 神经元。FT 神经元具有时序记忆功能，使得其可以处理更加复杂的数据。并使用了复数运算模型巧妙地使神经元的两部分可以协同运算与更新。经测试，该模型在不同任务上均取得了不错的效果，在同等规模的前提下，甚至优于之前最优的神经网络[35]。

<!-- 这里可以加 FT 神经元的图 -->

### 2.2 神经网络的优化方法

由于神经网络的输出结果 $\hat{y}$ 是与预期的输出结果 $y$ 有一定的误差的，这个误差的大小使用误差函数来描述，比如常用的均方误差（Mean Squared Error, MSE）就是计算实际输出与预期输出之间差值的平方和。为了使得神经网络的输出结果更加地精确，需要对神经网络的参数进行优化，常用的神经网络优化算法有误差逆传播算法、遗传算法、模拟退火算法等等。

#### 2.2.1 误差逆传播优化算法

误差逆传播（error BackPropagation，简称 BP）算法是如今最有效且最常用的神经网络优化算法[7]。BP 算法基于梯度下降（gradient descent）策略，以目标的负梯度方向对参数进行调整，对于误差 $E_k$，在一次迭代后参数 $w_{hj}$ 的变化量为 $\Delta w_{hj} = -\eta \frac{\partial E_k}{\partial w_{hj}}$，其中 $\eta$ 为学习率。BP 算法根据误差对各个参数的梯度大小对参数分别调整，使得各个参数能够根据各自的“贡献”调整得恰到好处，提高算法的收敛速度与性能。

最基本的梯度下降法是对整个数据集遍历后计算梯度并进行更新的，这种方法也被称为批量梯度下降法（batch gradient descent, BGD）。由于每次更新都是针对整个数据集，所以不仅计算量大，而且会消耗大量的内存。另外，整个数据集不同数据之间的梯度存在一定的抵消现象，这就使得批量梯度下降法收敛非常慢。另外一种梯度下降法与批量梯度下降法恰恰相反，它每次对一对数据进行更新，这种方法称为随机梯度下降法（Stochastic gradient descent, SGD）。由于每遍历一个数据对就会计算梯度并更新参数，这使得随机梯度下降法对计算设备的性能要求更低，同时也使得网络收敛的更加快速。但由于每对数据都是有一定的随机性的，更新过程中伴随着较大的噪声，所以随机梯度下降并不是每次迭代都向着整体最优化方向，更新的路线会较为曲折。为了综合上述两者的优点，小批量梯度下降法（Mini-batch gradient descent）每次采用一小批数据对网络进行更新，该方法不仅解决了批量梯度下降法收敛慢的问题，又解决了随机梯度下降法噪声多的问题，这也是神经网络更新中最常用的方法。

<!-- 这里可以加 SGD BGD 区别的图 -->

#### 2.2.2 启发式优化算法

BP 优化算法虽然能够非常有效地降低网络误差，但是它只是一种局部搜索算法，在训练过程中非常容易陷入局部最优的位置，导致进一步优化困难等问题。为了跳出局部极小以尽可能地逼近全局最小，人们常采用遗传算法（genetic algorithms, GA）、模拟退火（simulated annealing, SA）算法来逼近全局最优。

![Figure 2.4](../_media/paper/Figure2.4.jpg)

图 2.4 网络优化时的全局最小与局部极小

遗传算法（Genetic Algorithm, GA）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。它以个体（individual）为优化对象，以种群（population）为搜索空间，通过选择（selection）、交叉（crossover）与变异（mutation）选取出更优的个体。其本质是一种高效、并行、全局搜索的方法，能在搜索过程中自动获取和积累有关搜索空间的知识，并自适应地控制搜索过程以求得最佳解。

<!-- 这里可以考虑是否详述 GA -->

模拟退火算法（simulated annealing, SA）是对冶金学退火过程进行模拟的算法。它将热力学的理论用在统计学上，将搜寻空间内每一点想像成金属内的原子，将该位置的合适程度作为该原子的能量，而到达相邻位置的概率取决于两点“能量”之差。可以证明，模拟退火算法所得解依概率收敛到全局最优解。

此外，还有一些在 BP 优化的基础上进行优化的算法，比如 Momentum 优化等方法，上述方法都在一定程度上使得网络获得更好的性能，但由于这些技术大多都是启发式算法，理论上尚缺乏保障。

<!-- 这里可以考虑是否详述 Momentum -->

#### 2.2.3 神经网络的优化难点及解决方案

正由于神经网络具有强大的表示能力，神经网络经常遭遇过拟合问题。为了解决该问题，需要使用正则化（regularization）或 Early Stopping 等方案。

在网络训练初期，训练误差与验证误差往往是同时下降的，此时网络学到了比较泛化的表示。随着训练迭代次数的增加，网络可能会将训练集中独有的特征当作所有潜在样本所具有的一般特征，这将会导致网络泛化能力下降，这便是过拟合现象。这在误差上表现为训练误差仍在下降而验证误差不下降或反而上升。为了使得模型学习到最泛化的表示，可以在刚刚发生过拟合时停止网络的训练，这便是 Early Stopping。

另外，网络能够过拟合的主要原因是网络具有极高的拟合能力，如果能够限制网络的拟合能力，那么网络将会更倾向于学习泛化的表示。该方式被称为正则化，常用的正则化方法有 L2 正则化与 dropout。L2 正则化方式通过降低权重的 L2 范数以达到限制模型的拟合能力，提高模型的泛化能力。dropout 在训练过程中随机使某些神经元失活的情况下依然要求神经网络输出预期结果，使得整个网络不过分依赖于任一个神经元，从而减弱过拟合现象[8]。

梯度弥散（vashing gradient）问题是一种在深度神经网络中常见的问题，当使用反向传播方法计算导数的时候，随着网络的深度的增加，反向传播的梯度的梯度值会急剧地减小。由于 BP 神经网络早期使用的激活函数是具有饱和特性的 Sigmoid，其在较小或者较大的输入时导数趋于 0，也就导致了梯度无法传递，参数不能得到更新。

在深度学习崛起的前夕，有两个深度模型突破了限制，达到了更深的网络结构，一个是深度信念网络（deep belief network，DBN）[9]，一个是堆叠自编码器（stacked auto encoder）。两者有着相似的结构与训练方式，前者是由多个受限玻尔兹曼机（Restricted Boltzmann Machine，RBM）相互堆叠后添加一个分类器而成，后者是由多个自编码器（auto encoder，AE）堆叠而成，它们的训练方式都是先进行逐层无监督预训练（pre-training），后使用有监督的微调（fine-tuning）。这种训练方式的有效性主要来源于无监督预训练可以降低网络的方差，起到了一定的正则化效果。另一方面，随机梯度下降的网络训练的早期行为会造成很大的影响，这可能导致后期无论多少次迭代都无法跳出某一个局部最小，而无监督预训练能够将网络参数初始化在一个较好的位置，使其更加接近全局最优[10]。然而该方法并没有解决梯度弥散的问题，所以神经网络的深度仍然非常受限。但该方法确实可以在一定程度上提高模型的精度，而且在拥有大量无标签数据与少量有标签数据的情况下，该方法是更为合适的选择，这种训练方式也被称为半监督学习（Semi-supervised learning）。

为了解决梯度弥散的问题，Xavier Glorot 提出对参数进行合理的初始化以保证前向传播与反向传播时数据的分布不会发生太大改变[11]，随后 Geoffrey Hinton 提出使用 ReLU 作为激活函数[12]，这也是如今最常用的激活函数。但 ReLU 激活函数在负值时仍然没有梯度，会导致神经元死掉，Andrew Maas 提出了 LeakyReLU 激活函数进一步缓和了该问题[13]。但网络更深的时候，梯度弥散就会死灰复燃，何恺明在 ResNet 提出了残差训练的概念，极大地提高了神经网络的深度[14]。

### 2.3 深度神经网络研究及其应用现状

由于神经网络在结构上非常容易堆叠成多层结构，而神经网络的每一层非线性变换都会使得模型的的复杂程度提升，这就使得深层网络有着明显更高的表示能力。因此，提高神经网络深度的极限是近年来神经网络研究的一个热门方向，由此也演变出来了深度学习这一门新的学科。深度神经网络非常适合高维结构化数据的处理，它使得人们不必纠结于高维数据的繁杂处理步骤，只需要定义输入与输出即可获得一个准确的预测模型，神经网络便会自行选用合适的方式对数据进行处理。现如今诸如计算机视觉、自然语言处理等等很多复杂的学习任务都交由深度神经网络来处理，且均取得了重大的突破。

#### 2.3.1 神经网络在计算机视觉的研究与应用现状

神经网络在很早以前就已经应用于计算机视觉任务中了，人们最初尝试的是传统的神经网络，但由于传统神经网络模型并没考虑到图片各个像素点之间的空间关联性，这就使得神经网络拥有过多的参数，同时非常难以训练，很难应用于实际生产中。后来卷积神经网络的发明与应用彻底改善了这一问题，神经网络不仅在计算机视觉中广泛应用，甚至达到了超越人类水准的分类辨识能力。

卷积神经网络（Convolutional Neural Network, CNN）与经典神经网络类似，它参考了生物视觉神经元的结构，能够很好地处理视觉相关问题。

1980 年，Kunihiko Fukishima 提出的 Neocognitron[41] 创造性地从人类视觉系统引入了许多新的思想到人工神经网络，被广泛认为是 CNN 的雏形。1990 年，LeCun 将反向传播应用到了类似 Neocoginitro 的网络上来做监督学习[42]。LeCun 的网络结构中引入了权值共享的概念，空间上不同位置的神经元使用同一个卷积核进行卷积。权值共享大大地减少了参数量，也就降低了过拟合的风险，提高了模型的泛化能力，另外也使得训练的速度大大提升。1998 年，LeCun 提出的 LeNet-5[43] 技压群雄，轻松超过其它主流的机器学习算法。但由于当年计算能力的限制和后来 SVM 的大放异彩，CNN 在 21 世纪初迷失了近十年。

![Figure 2.5](../_media/paper/Figure2.5.png)

图 2.5 LeNet-5 网络结构

LeNet-5 的网络结构已经与现在人们常用的卷积神经网络结构非常相似，它主要主要包含卷积层与池化层。卷积层是对图片上局部像素值进行加权求和，建立一个局部感受野，降低网络参数量。如图 1.5 所示，卷积核扫描过图片时对图片相应位置进行加权求和，将所得值作为输出“图片”相应位置的值，之后通过卷积核不断移动，扫描得到完整的输出“图片”。输出的“图片”称为特征映射（feature map），经过卷积后的 feature map 表示了更复杂的特征[37]。而池化层是对图片进行下采样，降低图片的大小，从而在减少数据量的同时尽可能地保留有用的信息[5]。

![Figure 2.6](../_media/paper/Figure2.6.jpg)

图 2.6 卷积层

随着计算机硬件的快速发展，硬件的计算能力不断提升，神经网络的训练逐渐成为了可能。2006 年，研究人员成功利用 GPU 加速了 CNN，相比 CPU 实现快了近四倍。2012 年，AlexNet[44] 在 ImageNet 大规模识别挑战赛（ImageNet Large Scale Visual Recognition Competition，ILSVRC）图片分类任务上以 15.3% 的 Top-5 错误率登顶，远高于第二名的 26.2%。AlexNet 基本结构参考了 LeNet-5，同时为了防止梯度弥散（vashing gradient）等问题使用了 ReLU 激活函数[12]。AlexNet 使得 CNN 再度被人们所重视，也标志着神经网络的复苏与深度学习的崛起。

随后几年，CNN 迎来了快速发展的浪潮，新的网络结构层出不穷，效果也在不断提升。2014 年，google 提出的 GoogleNet[45] 和 Visual Geometry Group 提出的 Vgg[46] 分别在 ILSVRC2014 位列第一和第二。后者在 AlexNet 的基础上进一步提高网络深度，前者则在网络结构上另辟蹊径，不仅能够提高网络深度，而且大大减少网络参数量。2015 年，何恺明提出的 ResNet 利用残差结构使得网络能在不退化的前提下提升到 152 层[14]，一举摘得 ILSVRC2015 桂冠。此后几年，google 在 GoogLeNet 提出的 Inception 结构和何恺明提出的 ResNet 成为了 CNN 两个主要发展的方向。google 在 Inception 结构的基础上提出了 InceptionV2、InceptionV3、Xception、InceptionV4、Inception-ResNet、Inception-ResNetV2 结构，不断提升网络的性能，后两者融合了 ResNet 的残差结构，使得网络性能进一步提升。何恺明也相继提出了 ResNetV2、ResNeXt，后者也在结构中借鉴了 Inception 结构。2017 年，GaoHuang 提出的 DenseNet 结构建立了比 ResNet 更加密集的连接，并提出了特征重用的概念，不仅能够解决梯度弥散等问题，还进一步减少了参数量[47]。同年，Jie Hu 提出的 SE-Net 利用通道注意力机制进一步优化 ResNeXt 结构[48]，一举夺得 ILSVRC2017 同时也是最后一届 ILSVRC 的桂冠。

神经网络的研究极大地推动了计算机视觉的发展，它使得原来很多不可能的任务成为了现实，如今神经网络已经在很多任务上达到甚至超越人类的表现，这让我们看到了深度学习研究的无限可能。

<!--

#### 2.3.2 神经网络在自然语言处理的研究与应用现状

看情况添加，毕竟焊接与此无关

-->

#### 2.3.2 深度强化学习研究与应用现状

强化学习（Reinforcement learning, RL）是机器学习和人工智能的一个分支，专注于目标导向的学习和决策。强化学习不同于传统有监督的机器学习任务，在最开始是没有可供训练的数据的，而数据的获取是通过机器与环境之间的交互逐渐获得的。在与问题或环境的持续互动中，强化学习智能体采取行动并观察所得的奖励，智能体根据这些观察结果来改变其选择动作的方式，以达到学习的效果。简而言之，监督学习就是教书式的学习，而强化学习则是在实践中进行摸索式的学习。

强化学习主要分为基于模型（model-based）、基于值（value-based）、基于策略（policy-based）三种学习方式。基于模型的学习方法是让智能体自己学习出来一个能够从它的观察角度描述环境是如何工作的模型，然后利用这个模型来进行动作的规划。也就是说基于模型的方法需要对环境进行建模，建模的好坏则直接影响了最终决策的优劣。然而事实上很多情况并不需要对环境进行建模就可以找到最优的策略，基于值的学习方式与基于策略的学习方式就是最好的证明。基于值的学习方式是让智能体能够更加准确地进行自我评价，智能体可以在采取行动之前就意识到自己改行动的好坏，进而及时调整行为。基于策略的学习方式则是直接让智能体学习在某一环境下自己应当采取何种行为。这三种方式并非完全割裂的，事实上模型、值与策略刚好是强化学习智能体的三个重要组成部分，而三种不同的学习方式只是学习的关注点不同而已。

最近几年强化学习的常用方法也在逐渐转变，过去常用的方法是基于模型的学习方法，而近期的研究中已经很少使用该方法，更多使用的是基于值与基于策略的学习方法。自 12 年 Actor-Critic 算法[52]被提出，研究的热点也转向了基于值与基于策略相结合的方法。此后，2013 DeepMind 提出 A3C 算法，通过多线程异步训练的方法解决了数据时间相关性的问题，使得 Actor-Critic 网络训练更加容易[53]。

近年来深度学习的崛起也是极大地推动了强化学习的研究，强化学习的研究重心也在逐渐向深度强化学习转变。13 年 Volodymyr Mnih 等人提出的 Deep Q-Network 成功地将深度学习方法应用在基于值的学习方法 Q-learning 上，被人们认为是深度强化学习的开山鼻祖[49]。15 年到 16 年 DeepMind 推出的 AlphaGo 先后击败了欧洲围棋冠军华裔法籍职业棋手樊麾二段与世界冠军韩国职业棋手李世石九段，这使得人们真正地意识到人工智能的能力，AlphaGo 也被誉为人工智能研究的标志性进展。AlphaGo 采用蒙特卡洛树搜索与深度神经网络相结合，其中神经网络的训练一方面使用了人类棋谱来进行监督训练，另一方面采用了基于模型、基于值与基于策略三种方法相结合的强化学习方法[50]。此后，DeepMind 再次推出 AlphaGo Zero，抛弃从人类棋谱中进行监督学习的方法，而是从零开始，不断进行自我对弈，这使得学习速度大大提升，仅仅 40 天就超过之前所有版本的水平[51]。

深度强化学习最近今年在不同领域大显神通，比如在视频游戏、棋类游戏上打败人类顶尖高手，控制复杂的机械进行操作，调配网络资源，为数据中心大幅节能，甚至对机器学习算法自动调参。各大高校和企业纷纷参与其中，提出了眼花缭乱的 DRL 算法和应用。DeepMind 负责 AlphaGo 项目的研究员 David Silver 甚至喊出认为结合了 DL 的表示能力与 RL 的推理能力的 DRL 将会是人工智能的终极答案。然而强化学习仍然是具有非常多的局限性的，比如样本利用率非常低，好的奖励函数难以设计，难以平衡“探索”和“利用”，对环境的过拟合等等问题，这些问题严重地阻碍了深度强化学习的发展，因此这些问题将会是深度强化学习今后的研究重点。

## 3 神经网络在焊接领域的应用研究现状

### 3.1 机器学习算法在焊接领域的研究现状

<!-- 机器学习算法在预测过程的应用现状 -->

机器学习是人工智能的一个分支，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。机器学习目前已经广泛应用于数据挖掘、计算机视觉、自然语言处理、医学诊断、语音和手写识别等等领域。

![Figure 3.1](../_media/paper/Figure3.1.png)

图 3.1 机器学习的基本流程

机器学习在医疗诊断上有着广泛的应用，目前在药剂化学性质、认知行为疗法、链路预测问题、全身骨闪烁图、早期诊断、严重性预测器、代谢组学研究和基因组挖掘等方面有着非常高的研究热度[15]，且在医学影像、临床决策支持、语音识别、药物挖掘、健康管理、病理学等众多领域取得突破性进展[16]，这对提高医疗系统诊断准确性、安全性和可靠性有着重要帮助。

机器学习在化学领域也有着很多的应用，它可以帮助分子和材料的设计、合成与表征，以加速科研的研究进程[17]。在化学合成中，需要人类专家来指定特定的条件和上下步的规则，这些规则在给定的步骤中排除了大量可能用到的试剂,限制了可供选择的算法数量。如果依赖于传统算法的机器要与专家竞争，那么上下步规则（通常是数千个）就显得至关重要。深度学习方法对预测化学合成路径表现出特殊的应用前景，其通过将基于规则的专家系统和神经网络相结合的方案来实现这一目的，而该神经网络是对候选合成路径的排序或者是通过应用规则对预测产物的可能性进行组合而生成的。此外，机器学习还能够帮助研究者发现新型化合物、辅助多维表征、甚至加强理论化学。

当今机器学习最主要的算法是神经网络，由于其具有强大的拟合能力，且很容易堆叠多层，因此在此基础上产生了深度学习这一学科。深层神经网络往往有着比其他机器学习算法更高的性能，这使得它非常适合处理图像、语音、文本等复杂数据，因此被广泛应用于图像分类与识别、语音识别、自然语言处理等等领域。

<!-- 焊接过程预测技术研究现状 -->

如果能够对焊接过程进行预测，那么就能够通过调整焊接参数来提高焊接质量。但由于焊接过程涉及多种复杂因素，很难人工推导出对焊接结果的预测公式，因此常需要机器学习技术对已有数据进行拟合，获得较为准确的预测模型。其中，机器学习常用算法有决策树（decision tree）、支持向量机、神经网络、k 近邻（k-nearest neighbor，k-NN）算法等。

<!-- 其它机器学习算法在焊接过程预测的应用 -->

支持向量机可以在高维空间中构造超平面以最大程度地将两类数据分离，支持向量机会最大化两类数据相对于这个超平面之间的距离，这个距离被称为间隔（margin），因此这种线性分类器也常被成为最大间隔分类器[29]。然而这种线性分类器无法对非线性数据进行划分，所以需要在其基础上应用一个核函数，使 SVM 具有非线性分类的能力。由于 SVM 相比于 logitic 回归拥有更加简单的数学表示形式，所以 SVM 在小型的分类任务上往往会有着更好的效果和训练速度。顾盛勇在焊缝视觉检测系统中使用了 SVM 预测焊缝位置，并利用 PCA 算法进行优化[30]。贺峰等人基于多传感器和 SVM 对焊接过程进行模式识别，有效地提高了焊接过程准确率[31]。

随机森林算法也是一种机器学习任务中的常用方法。随机森林算法是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定。它对多种数据都能较好地进行分类，但是在类别特别多时它的表现并不会太好。Zhifen Zhang 等人首先使用 PCA 算法对数据进行降维处理，之后使用 RF 进行分类，有效地对焊缝缺陷种类进行预测[32]。Haixing Zhu 等人首先利用 CNN 对熔池图片进行降维，之后使用 RF 进行了有效的分类[33]。

### 3.2 神经网络在焊接工艺控制中的应用现状
### 3.3 神经网络在焊接性能预测的应用现状
### 3.4 神经网络在焊接结构分析中的应用现状

<!-- 神经网络在焊接过程预测的应用现状 -->

神经网络是一种非常有效的机器学习算法，它拥有非常强大的学习能力，可以轻松从数据集中发现潜在规律，将神经网络应用于焊接领域中的焊接工艺参数选择与优化、焊缝跟踪、焊接缺陷预测、力学性能预测等都具有比较理想的效果[18]。

传统的 BP 神经网络在焊接预测中已经有着广泛的应用，均取得了不错的效果。张抱日等人利用 BP 神经网络建立了焊接高度与电弧电压的对应关系模型，并进一步实现了焊接高度的自动控制[19]。赵成涛建立了基于 BP 神经网络的镁合金焊缝成形预测模型，利用神经网络的映射能力和分析能力，采用焊接过程的焊接电流、焊接电压、焊接速度、焊丝干伸长作为预测输入，把焊缝成形中的焊缝熔深、熔宽、余高作为信息输出对神经网络进行训练，从而建立基于 BP 神经网络的焊接参数和焊缝成形的映射模型[20]。黄军芬等人利用 BP 神经网络建立了熔池形貌与背面熔宽的模型，对熔透情况进行了预测[21]。Limeng Yin 等人利用双隐层神经网络对焊缝尺寸进行了预测，在网络的设计细节中使用了较新的深度学习技术，取得了较高的预测精度[22]。

虽然传统的 BP 神经网络已经能够取得不错的效果，但由于其本质是一种局部搜索方法，很容易陷入局部最优，使得网络泛化能力下降。遗传算法起源于对生物系统所进行的计算机模拟研究。它是模仿自然界生物进化机制发展起来的随机全局搜索和优化方法，借鉴了达尔文的进化论和孟德尔的遗传学说。Bowen Liu 搭建神经网络来拟合焊接参数与焊接缺陷的映射关系，并使用遗传算法进行优化，并进一步搜索焊接缺陷最低时对应的焊接参数，最终焊接成品有着较好的质量[23]。

遗传算法不仅可以独立使用，还可以结合 BP 算法进一步提高模型的精度，其方法是首先利用遗传算法优化神经网络参数达到一个较优的效果，然后以此为 BP 优化的起点，使用梯度下降法进一步训练以降低误差。该方法被称为 BP-GA 方法，它结合了 GA 和 BP 的优点，首先在全局范围内为 BP 设置了一个比较好的起点，使得之后的 BP 优化能够更加接近全局最优。张喆等人利用 BP-GA 的方法拟合了焊接前进方向温度预测模型和前进侧方向温度预测模型，其预测能力要优于基于传统 BP 神经网络所建立的模型[24]。刘立鹏等人利用 BP-GA 算法对焊接接头力学性能进行预测，达到了预期的精度要求[25]。Hua Ding 等人利用 BP-GA 算法对焊接残余厚度进行了预测，使得网络的预测精度更加准确，收敛速度大大提高[26]。

![Figure 3.2](../_media/paper/Figure3.2.jpg)

图 3.2 BP-GA 神经网络权值阈值优化流程

此外，无监督预训练也能够显著提高神经网络的性能。稀疏自编码器（sparse auto encoder，SAE）是自编码器的一种变体，它对参数添加了一个惩罚项，使得被激活的神经元限制数量限制在一个较低的值，换言之，网络会学习到较为稀疏的表示，而稀疏的表示能够在编码时更加有效地对数据进行降维。堆叠稀疏自编码器（stacked sparse auto encoder，SSAE）是由稀疏自编码器堆叠而成的，它相比于堆叠自编码器拥有更好的降维效果，可以学习到更有用的特征。Yanxi Zhang 等人利用 SSAE 对焊接状态进行预测，之后使用 GA 进行超参数搜索，取得了一定的效果，并将该方法称为 SSAE-GA 方法[27]。

![Figure 3.3](../_media/paper/Figure3.3.png)

图 3.3 SSAE-GA 对神经网络的优化流程

与 SAE 相似，还有一种相似的自编码器被称为降噪自编码器（denoising auto encoder），堆叠后的结构即 SDAE，SDAE 能够从包含噪声的数据中还原数据，因此有着更强的鲁棒性。Johannes Gunther 等人在图像特征提取过程中使用了 SDAE，并使用提取出的特征进行了 SVM 分类测试，仅产生了较低的分类误差。这些提取出的特征用于后续焊接控制神经网络的输入，取得了较好的控制效果[28]。

<!-- 卷积神经网络熔池特征提取研究 -->

随着深度学习技术近年来迅速发展，基于卷积神经网络的熔池形态预测方法也逐渐兴起。卷积神经网络中的特征提取和模式分类同时进行，对图像的位移、缩放、倾斜及其它形式的扭曲变形都具有良好的不变性和等变性[36]。而且卷积神经网络有着很强的学习能力与自适应能力，相对于传统的边缘提取技术，它拥有更高的鲁棒性与更快的处理速度。

深度学习的多层堆叠、每层对上一层的处理机制可以看作对输入信号进行逐层加工，从而把初始的输入表示一步步转化为与输入目标更为密切的表示，由此可将深度学习理解为特征学习[5]。较低的层次处理一些简单的诸如边缘、形状、颜色之类的特征，而在高层，低层特征组合出来更为复杂的对象特征，诸如眼睛、嘴、耳朵等等[37]。因此即便输出结果有所不同，神经网络在前几层也会做几乎相同的特征提取任务。

近几年有很多利用卷积神经网络进行熔透预测的相关研究，其本质上也是低层网络从熔池图像中提取出有用的特征，交由高层预测模块进行预测。李海超等人使用卷积神经网络对熔透状态进行了预测，并对卷积层的特征映射进行了可视化，对熔透预测模型的依据进行了一定的解释。刘新锋利用基于 ImageNet 预训练的 AlexNet，对穿孔状态及熔透状态进行预测，取得了较高的准确率[38]。

也有一些研究使用卷积神经网络直接将熔池图像特征进行压缩，提取出较低维度的特征信息，作为后续预测步骤的一部分信息。覃科等人利用卷积神经网络对熔池特征进行提取，交由后续支持向量机（support vector machine，SVM）分类器进行分类预测，两者同步训练，以预测焊接熔池的状态信息。他们同时还使用了传统的 BP 神经网络直接进行预测，对比结果显示卷积神经网络明显有着更高的准确率和鲁棒性[39]。Haixing Zhu 等人利用卷积神经网络对焊缝表面图像进行特征提取，交由后续随机森林（Random Forest，RF）算法进行分类，优于直接在 CNN 后接 Softmax 分类层的效果[40]。

![Figure 3.4](../_media/paper/Figure3.4.png)

图 3.4 熔池状态识别的卷积神经网络结构

## 4 神经网络在焊接领域应用研究的发展趋势

<!-- 趋势嘛，就是深度神经网络 -->

### 4.1
### 4.2
## 结论

# Refs

1. 王田苗. 我国工业机器人技术现状与产业化发展战略
2. 邱葭菲. TIG 打底焊工艺研究
3. 霍厚志. 我国焊接机器人应用现状与技术发展趋势
4. 孟宪伟. 焊接智能化的研究现状及应用
5. 周志华. 机器学习
6. M-P 神经元论文
7. BP 论文
8. dropout2012
9. 无监督优化 RBM 论文 2006
10. Dumitru Erhan. Why Does Unsupervised Pre-training Help Deep Learning?
11. Xavier Glorot 初始化
12. ReLU 的论文
13. Leaky ReLU
14. ResNet
15. 张景奇. 机器学习在医疗和公共卫生中应用
16. 互联网医疗健康产业联盟. 2018 年医疗人工智能技术与应用白皮书[R]. 2018.
17. Butler K T,Davies D W,Cartwright H,et al. Machine learning for molecular and materials science[J]. Nature,2018,559(7715).
18. 裴浩东．人工神经网络及其在焊接中的应用
19. 张抱日. 基于焊缝熔透检测的机器人深熔 K-TIG 焊接系统
20. 赵成涛. 基于 BP 神经网络的镁合金焊缝成形预测
21. 黄军芬. 基于视觉传感的 GMAW 熔透状态预测
22. Limeng Yin. Prediction of weld formation in 5083 aluminum alloy by twin-wire CMT welding based on deep learning
23. Bowen Liu. Optimal design for dual laser beam butt welding process parameter using artificial neural networks and genetic algorithm for SUS316L austenitic stainless steel
24. 张喆. 基于遗传 BP 神经网络的搅拌摩擦焊温度模型
25. 刘立鹏. 基于遗传神经网络的焊接接头力学性能预测系统
26. Hua Ding. Research on laser processing technology of instrument panel implicit weakening line based on neural network and genetic algorithm
27. Yanxi Zhang. Real‑time monitoring of high‑power disk laser welding statuses based on deep learning framework
28. Johannes Gunther. Intelligent Laser Welding through Representation, Prediction, and Control Learning: An Architecture with Deep Neural Networks and Reinforcement Learning
29. 统计学习方法. 李航
30. 顾盛勇. 基于视觉传感的高效深熔锁孔TIG焊焊缝识别及熔透状态的研究
31. 贺峰. 基于多传感器和支持向量机的 GMAW 焊接过程模式识别研究
32. Zhifen Zhang. Real-time seam defect identification for Al alloys in robotic arc welding using optical spectroscopy and integrating learning mechanisms in 20kw-class CO2 laser welding processes[J]. Journal of Physics D:Applied Physics, 2002, 36(2): 192.
33. Haixing Zhu. Deep Learning-Based Classification of Weld Surface Defects
34. Matthew D. Zeiler. Visualizing and Understanding Convolutional Networks
35. Flexible Transmitter Network
36. Krizhevsky A，Sutskever I，Hinton GE. ImageNet classification with deep convolutional neural networks[C]. Advances in Neural Information Processing Systems, Curran Associates RedHook,NY,USA,2012:1097-1105．
37. Matthew D. Zeiler. Visualizing and Understanding Convolutional Networks
38. 刘新锋. 基于正面熔池图像和深度学习算法的PAW穿孔/熔透状态预测
39. 覃科. 基于卷积神经网络的CO2 焊接熔池图像状态识别方法
40. Haixing Zhu. Deep Learning-Based Classification of Weld Surface Defects
41. Fukushima. Neocognitron
42. LeCun. Handwritten digit recognition with a back-propagation network
43. LeCun. Gradient-Based Learning Applied to Document Recognition
44. ImageNet Classification with Deep Convolutional Neural Networks
45. GoogLeNet 的论文
46. vgg 的论文
47. DenseNet
48. SE-Net
49. DQN 论文
50. AlphaGo 论文（没下）
51. AlphoGo Zero 论文（没下）
52. Actor-Critic
53. A3C 算法
